{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:04:58.752069Z","iopub.execute_input":"2024-08-04T04:04:58.752655Z","iopub.status.idle":"2024-08-04T04:05:05.316203Z","shell.execute_reply.started":"2024-08-04T04:04:58.752625Z","shell.execute_reply":"2024-08-04T04:05:05.315173Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset and Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(), # Convert images to tensors\n    transforms.Normalize((0.5,), (0.5,)) # Normalize the images to [-1, 1]\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:05.318208Z","iopub.execute_input":"2024-08-04T04:05:05.318588Z","iopub.status.idle":"2024-08-04T04:05:05.323131Z","shell.execute_reply.started":"2024-08-04T04:05:05.318563Z","shell.execute_reply":"2024-08-04T04:05:05.322262Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load MNIST training dataset\ntrain_dataset = torchvision.datasets.MNIST(\n    root='./data', train=True, download=True, transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:05.324701Z","iopub.execute_input":"2024-08-04T04:05:05.324945Z","iopub.status.idle":"2024-08-04T04:05:08.240029Z","shell.execute_reply.started":"2024-08-04T04:05:05.324923Z","shell.execute_reply":"2024-08-04T04:05:08.239063Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 38968522.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1067350.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 9352990.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 3707771.27it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load MNIST test dataset\ntest_dataset = torchvision.datasets.MNIST(\n    root='./data', train=False, download=True, transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:08.242907Z","iopub.execute_input":"2024-08-04T04:05:08.243402Z","iopub.status.idle":"2024-08-04T04:05:08.257372Z","shell.execute_reply.started":"2024-08-04T04:05:08.243355Z","shell.execute_reply":"2024-08-04T04:05:08.256703Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for training set\ntrain_loader = DataLoader(\n    dataset=train_dataset, batch_size=64, shuffle=True\n)\n\n# Create DataLoader for test set\ntest_loader = DataLoader(\n    dataset=test_dataset, batch_size=64, shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:08.258521Z","iopub.execute_input":"2024-08-04T04:05:08.258850Z","iopub.status.idle":"2024-08-04T04:05:08.263860Z","shell.execute_reply.started":"2024-08-04T04:05:08.258820Z","shell.execute_reply":"2024-08-04T04:05:08.263064Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Modifying ResNet model for MNIST dataset","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\n# Load the pre-trained ResNet18 model\nmodel = models.resnet18(pretrained=True)\n\n# Modify the first convolutional layer to accept 1 channel (grayscale)\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# Modify the fully connected layer for 10 output classes (MNIST)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)\n\n# Move model to the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:08.265155Z","iopub.execute_input":"2024-08-04T04:05:08.265538Z","iopub.status.idle":"2024-08-04T04:05:09.295144Z","shell.execute_reply.started":"2024-08-04T04:05:08.265509Z","shell.execute_reply":"2024-08-04T04:05:09.293931Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 146MB/s] \n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model Setup","metadata":{}},{"cell_type":"code","source":"# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:09.297886Z","iopub.execute_input":"2024-08-04T04:05:09.298729Z","iopub.status.idle":"2024-08-04T04:05:09.304180Z","shell.execute_reply.started":"2024-08-04T04:05:09.298699Z","shell.execute_reply":"2024-08-04T04:05:09.303192Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"# Number of epochs\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # Print loss for the epoch\n    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:05:09.305489Z","iopub.execute_input":"2024-08-04T04:05:09.305806Z","iopub.status.idle":"2024-08-04T04:09:40.365490Z","shell.execute_reply.started":"2024-08-04T04:05:09.305779Z","shell.execute_reply":"2024-08-04T04:09:40.364554Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.1790\nEpoch [2/10], Loss: 0.0691\nEpoch [3/10], Loss: 0.0533\nEpoch [4/10], Loss: 0.0451\nEpoch [5/10], Loss: 0.0407\nEpoch [6/10], Loss: 0.0360\nEpoch [7/10], Loss: 0.0278\nEpoch [8/10], Loss: 0.0253\nEpoch [9/10], Loss: 0.0247\nEpoch [10/10], Loss: 0.0203\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing Loop","metadata":{}},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = correct / total\nprint(f'Accuracy on the test set: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:09:40.366594Z","iopub.execute_input":"2024-08-04T04:09:40.366919Z","iopub.status.idle":"2024-08-04T04:09:43.311588Z","shell.execute_reply.started":"2024-08-04T04:09:40.366893Z","shell.execute_reply":"2024-08-04T04:09:43.310575Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Accuracy on the test set: 98.83%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Saving the Model","metadata":{}},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), 'mnist_resnet18.pth')\nprint(\"Model saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T04:09:43.314271Z","iopub.execute_input":"2024-08-04T04:09:43.314586Z","iopub.status.idle":"2024-08-04T04:09:43.406841Z","shell.execute_reply.started":"2024-08-04T04:09:43.314559Z","shell.execute_reply":"2024-08-04T04:09:43.405931Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}