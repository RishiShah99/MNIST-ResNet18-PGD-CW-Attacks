{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.195623Z","iopub.execute_input":"2024-08-04T14:43:55.196393Z","iopub.status.idle":"2024-08-04T14:43:55.200673Z","shell.execute_reply.started":"2024-08-04T14:43:55.196363Z","shell.execute_reply":"2024-08-04T14:43:55.199611Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset and Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(), # Convert images to tensors\n    transforms.Normalize((0.5,), (0.5,)) # Normalize the images to [-1, 1]\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.202684Z","iopub.execute_input":"2024-08-04T14:43:55.202986Z","iopub.status.idle":"2024-08-04T14:43:55.209003Z","shell.execute_reply.started":"2024-08-04T14:43:55.202952Z","shell.execute_reply":"2024-08-04T14:43:55.208129Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Load MNIST training dataset\ntrain_dataset = torchvision.datasets.MNIST(\n    root='./data', train=True, download=True, transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.210041Z","iopub.execute_input":"2024-08-04T14:43:55.210338Z","iopub.status.idle":"2024-08-04T14:43:55.285410Z","shell.execute_reply.started":"2024-08-04T14:43:55.210296Z","shell.execute_reply":"2024-08-04T14:43:55.284428Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Load MNIST test dataset\ntest_dataset = torchvision.datasets.MNIST(\n    root='./data', train=False, download=True, transform=transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.286515Z","iopub.execute_input":"2024-08-04T14:43:55.286788Z","iopub.status.idle":"2024-08-04T14:43:55.295448Z","shell.execute_reply.started":"2024-08-04T14:43:55.286765Z","shell.execute_reply":"2024-08-04T14:43:55.294614Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for training set\ntrain_loader = DataLoader(\n    dataset=train_dataset, batch_size=64, shuffle=True\n)\n\n# Create DataLoader for test set\ntest_loader = DataLoader(\n    dataset=test_dataset, batch_size=64, shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.298182Z","iopub.execute_input":"2024-08-04T14:43:55.298520Z","iopub.status.idle":"2024-08-04T14:43:55.306796Z","shell.execute_reply.started":"2024-08-04T14:43:55.298496Z","shell.execute_reply":"2024-08-04T14:43:55.305916Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Modifying ResNet model for MNIST dataset","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\n\n# Load the pre-trained ResNet18 model\nmodel = models.resnet18(pretrained=True)\n\n# Modify the first convolutional layer to accept 1 channel (grayscale)\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# Modify the fully connected layer for 10 output classes (MNIST)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)\n\n# Move model to the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.307889Z","iopub.execute_input":"2024-08-04T14:43:55.308131Z","iopub.status.idle":"2024-08-04T14:43:55.580404Z","shell.execute_reply.started":"2024-08-04T14:43:55.308110Z","shell.execute_reply":"2024-08-04T14:43:55.579447Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model Setup","metadata":{}},{"cell_type":"code","source":"# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.581713Z","iopub.execute_input":"2024-08-04T14:43:55.582120Z","iopub.status.idle":"2024-08-04T14:43:55.588418Z","shell.execute_reply.started":"2024-08-04T14:43:55.582085Z","shell.execute_reply":"2024-08-04T14:43:55.587542Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"# Number of epochs\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # Print loss for the epoch\n    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:43:55.589627Z","iopub.execute_input":"2024-08-04T14:43:55.589926Z","iopub.status.idle":"2024-08-04T14:48:20.085860Z","shell.execute_reply.started":"2024-08-04T14:43:55.589895Z","shell.execute_reply":"2024-08-04T14:48:20.084672Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.1791\nEpoch [2/10], Loss: 0.0695\nEpoch [3/10], Loss: 0.0554\nEpoch [4/10], Loss: 0.0484\nEpoch [5/10], Loss: 0.0377\nEpoch [6/10], Loss: 0.0305\nEpoch [7/10], Loss: 0.0320\nEpoch [8/10], Loss: 0.0233\nEpoch [9/10], Loss: 0.0219\nEpoch [10/10], Loss: 0.0220\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing Loop","metadata":{}},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = correct / total\nprint(f'Accuracy on the test set: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:48:20.087420Z","iopub.execute_input":"2024-08-04T14:48:20.087947Z","iopub.status.idle":"2024-08-04T14:48:22.839810Z","shell.execute_reply.started":"2024-08-04T14:48:20.087908Z","shell.execute_reply":"2024-08-04T14:48:22.838910Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accuracy on the test set: 99.13%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Saving the Model","metadata":{}},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), 'mnist_resnet18.pth')\nprint(\"Model saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:48:22.841218Z","iopub.execute_input":"2024-08-04T14:48:22.842031Z","iopub.status.idle":"2024-08-04T14:48:22.919858Z","shell.execute_reply.started":"2024-08-04T14:48:22.841998Z","shell.execute_reply":"2024-08-04T14:48:22.918935Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# PGD Adversarial Attacks onto the Model","metadata":{}},{"cell_type":"code","source":"pip install torchattacks","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:48:22.921223Z","iopub.execute_input":"2024-08-04T14:48:22.921667Z","iopub.status.idle":"2024-08-04T14:48:37.428979Z","shell.execute_reply.started":"2024-08-04T14:48:22.921632Z","shell.execute_reply":"2024-08-04T14:48:37.427896Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Collecting torchattacks\n  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.1.2)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (0.16.2)\nRequirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.11.4)\nRequirement already satisfied: tqdm>=4.56.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (4.66.4)\nCollecting requests~=2.25.1 (from torchattacks)\n  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.26.4)\nCollecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (2024.5.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->torchattacks) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\nDownloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: idna, chardet, requests, torchattacks\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.3\n    Uninstalling requests-2.32.3:\n      Successfully uninstalled requests-2.32.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.3 which is incompatible.\nconda 24.5.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\nconda 24.5.0 requires requests<3,>=2.28.0, but you have requests 2.25.1 which is incompatible.\ndatasets 2.20.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\ndocker 7.0.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-server 2.27.2 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torchattacks\nfrom torchattacks import PGD, CW","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:48:37.430522Z","iopub.execute_input":"2024-08-04T14:48:37.430835Z","iopub.status.idle":"2024-08-04T14:48:37.853466Z","shell.execute_reply.started":"2024-08-04T14:48:37.430806Z","shell.execute_reply":"2024-08-04T14:48:37.852605Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Define the model structure\nmodel = models.resnet18()\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)\n\n# Load the trained model weights\nmodel.load_state_dict(torch.load('mnist_resnet18.pth'))\nmodel.to(device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:48:37.854558Z","iopub.execute_input":"2024-08-04T14:48:37.854864Z","iopub.status.idle":"2024-08-04T14:48:38.156367Z","shell.execute_reply.started":"2024-08-04T14:48:37.854837Z","shell.execute_reply":"2024-08-04T14:48:38.155418Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\nimport time\n\n# Define the PGD attack\npgd = torchattacks.PGD(model, eps=0.3, alpha=2/255, steps=40)\n\n# Function to evaluate the model under attack with a progress bar\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    batch_times = []\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating\")\n    \n    for i, (inputs, labels) in progress_bar:\n        start_time = time.time()\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Enable gradients for the inputs\n        inputs.requires_grad = True\n        \n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Disable gradients for the inputs\n        inputs.requires_grad = False\n\n        batch_time = time.time() - start_time\n        batch_times.append(batch_time)\n        \n        # Update progress bar with batch accuracy and average batch time\n        progress_bar.set_postfix(batch_accuracy=(correct / total), avg_batch_time=sum(batch_times) / len(batch_times))\n    \n    accuracy = correct / total\n    return accuracy\n\n# Evaluate the model under PGD attack\nadv_accuracy = evaluate_under_attack(test_loader, model, pgd)\nprint(f'Adversarial Accuracy under PGD Attack: {adv_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:48:38.160418Z","iopub.execute_input":"2024-08-04T14:48:38.160678Z","iopub.status.idle":"2024-08-04T14:49:40.927237Z","shell.execute_reply.started":"2024-08-04T14:48:38.160656Z","shell.execute_reply":"2024-08-04T14:49:40.926287Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 157/157 [01:02<00:00,  2.50it/s, avg_batch_time=0.384, batch_accuracy=0.121]","output_type":"stream"},{"name":"stdout","text":"Adversarial Accuracy under PGD Attack: 12.13%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Carlini Wagner Attack","metadata":{}},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\nimport time\n\n# Define the Carlini-Wagner attack\ncw = torchattacks.CW(model, c=1e-4, kappa=0, steps=1000, lr=0.01)\n\n# Function to evaluate the model under CW attack with a progress bar\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    batch_times = []\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating\")\n    \n    for i, (inputs, labels) in progress_bar:\n        start_time = time.time()\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Enable gradients for the inputs\n        inputs.requires_grad = True\n        \n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Disable gradients for the inputs\n        inputs.requires_grad = False\n\n        batch_time = time.time() - start_time\n        batch_times.append(batch_time)\n        \n        # Update progress bar with batch accuracy and average batch time\n        progress_bar.set_postfix(batch_accuracy=(correct / total), avg_batch_time=sum(batch_times) / len(batch_times))\n    \n    accuracy = correct / total\n    return accuracy\n\n# Evaluate the model under CW attack\ncw_accuracy = evaluate_under_attack(test_loader, model, cw)\nprint(f'Adversarial Accuracy under CW Attack: {cw_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T14:49:40.928509Z","iopub.execute_input":"2024-08-04T14:49:40.928844Z","iopub.status.idle":"2024-08-04T15:23:15.964028Z","shell.execute_reply.started":"2024-08-04T14:49:40.928816Z","shell.execute_reply":"2024-08-04T15:23:15.963145Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 157/157 [33:35<00:00, 12.83s/it, avg_batch_time=12.8, batch_accuracy=0.396]","output_type":"stream"},{"name":"stdout","text":"Adversarial Accuracy under CW Attack: 39.59%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Visualizing All Images","metadata":{}},{"cell_type":"markdown","source":"## Visualizing Original Images with Labels","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Function to unnormalize and visualize images\ndef imshow(img, title=None):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    if title is not None:\n        plt.title(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:18.266435Z","iopub.execute_input":"2024-08-04T16:11:18.266777Z","iopub.status.idle":"2024-08-04T16:11:18.272432Z","shell.execute_reply.started":"2024-08-04T16:11:18.266750Z","shell.execute_reply":"2024-08-04T16:11:18.271393Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Visualize a few original dataset images with their labels\ndef visualize_original_images(loader, num_images=5):\n    dataiter = iter(loader)\n    images, labels = dataiter.next()\n    images, labels = images[:num_images], labels[:num_images]\n    imshow(torchvision.utils.make_grid(images), title=[str(int(label)) for label in labels])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:19.546181Z","iopub.execute_input":"2024-08-04T16:11:19.546507Z","iopub.status.idle":"2024-08-04T16:11:19.551838Z","shell.execute_reply.started":"2024-08-04T16:11:19.546484Z","shell.execute_reply":"2024-08-04T16:11:19.550935Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Visualize original images\nvisualize_original_images(test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.233137Z","iopub.status.idle":"2024-08-04T16:11:07.233563Z","shell.execute_reply.started":"2024-08-04T16:11:07.233339Z","shell.execute_reply":"2024-08-04T16:11:07.233357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing The Model's Predictions","metadata":{}},{"cell_type":"code","source":"# Visualize the model's predictions on original images\ndef visualize_model_predictions(model, loader, num_images=5):\n    model.eval()\n    dataiter = iter(loader)\n    images, labels = dataiter.next()\n    images, labels = images[:num_images], labels[:num_images]\n    images, labels = images.to(device), labels.to(device)\n\n    outputs = model(images)\n    _, predicted = torch.max(outputs, 1)\n    predicted = predicted.cpu().numpy()\n\n    imshow(torchvision.utils.make_grid(images.cpu()), title=[str(pred) for pred in predicted])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.236584Z","iopub.status.idle":"2024-08-04T16:11:07.236998Z","shell.execute_reply.started":"2024-08-04T16:11:07.236784Z","shell.execute_reply":"2024-08-04T16:11:07.236801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize model predictions on original images\nvisualize_model_predictions(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.246757Z","iopub.execute_input":"2024-08-04T16:11:07.247009Z","iopub.status.idle":"2024-08-04T16:11:07.269057Z","shell.execute_reply.started":"2024-08-04T16:11:07.246986Z","shell.execute_reply":"2024-08-04T16:11:07.267966Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize model predictions on original images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize_model_predictions\u001b[49m(model, test_loader)\n","\u001b[0;31mNameError\u001b[0m: name 'visualize_model_predictions' is not defined"],"ename":"NameError","evalue":"name 'visualize_model_predictions' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## Visualizing PGD Adversarial Attacks","metadata":{}},{"cell_type":"code","source":"# Visualize adversarial examples generated by PGD attack\ndef visualize_pgd_attack(model, loader, attack, num_images=5):\n    model.eval()\n    dataiter = iter(loader)\n    images, labels = dataiter.next()\n    images, labels = images[:num_images], labels[:num_images]\n    images, labels = images.to(device), labels.to(device)\n\n    adv_images = attack(images, labels)\n    outputs = model(adv_images)\n    _, predicted = torch.max(outputs, 1)\n    predicted = predicted.cpu().numpy()\n\n    imshow(torchvision.utils.make_grid(adv_images.cpu()), title=[str(pred) for pred in predicted])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.273636Z","iopub.execute_input":"2024-08-04T16:11:07.273887Z","iopub.status.idle":"2024-08-04T16:11:07.283886Z","shell.execute_reply.started":"2024-08-04T16:11:07.273865Z","shell.execute_reply":"2024-08-04T16:11:07.282914Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Define PGD attacks\npgd = torchattacks.PGD(model, eps=0.3, alpha=2/255, steps=40)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.285219Z","iopub.execute_input":"2024-08-04T16:11:07.285524Z","iopub.status.idle":"2024-08-04T16:11:07.314667Z","shell.execute_reply.started":"2024-08-04T16:11:07.285502Z","shell.execute_reply":"2024-08-04T16:11:07.313388Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define PGD attacks\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pgd \u001b[38;5;241m=\u001b[39m \u001b[43mtorchattacks\u001b[49m\u001b[38;5;241m.\u001b[39mPGD(model, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'torchattacks' is not defined"],"ename":"NameError","evalue":"name 'torchattacks' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Visualize PGD attack\nvisualize_pgd_attack(model, test_loader, pgd)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.315241Z","iopub.status.idle":"2024-08-04T16:11:07.315541Z","shell.execute_reply.started":"2024-08-04T16:11:07.315388Z","shell.execute_reply":"2024-08-04T16:11:07.315401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing CW Adversarial Attacks","metadata":{}},{"cell_type":"code","source":"# Visualize adversarial examples generated by CW attack\ndef visualize_cw_attack(model, loader, attack, num_images=5):\n    model.eval()\n    dataiter = iter(loader)\n    images, labels = dataiter.next()\n    images, labels = images[:num_images], labels[:num_images]\n    images, labels = images.to(device), labels.to(device)\n\n    adv_images = attack(images, labels)\n    outputs = model(adv_images)\n    _, predicted = torch.max(outputs, 1)\n    predicted = predicted.cpu().numpy()\n\n    imshow(torchvision.utils.make_grid(adv_images.cpu()), title=[str(pred) for pred in predicted])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.322346Z","iopub.execute_input":"2024-08-04T16:11:07.322597Z","iopub.status.idle":"2024-08-04T16:11:07.328822Z","shell.execute_reply.started":"2024-08-04T16:11:07.322575Z","shell.execute_reply":"2024-08-04T16:11:07.328008Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define CW attacks\ncw = torchattacks.CW(model, c=1e-4, kappa=0, steps=1000, lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.341605Z","iopub.execute_input":"2024-08-04T16:11:07.341852Z","iopub.status.idle":"2024-08-04T16:11:07.364852Z","shell.execute_reply.started":"2024-08-04T16:11:07.341831Z","shell.execute_reply":"2024-08-04T16:11:07.363605Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define CW attacks\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cw \u001b[38;5;241m=\u001b[39m \u001b[43mtorchattacks\u001b[49m\u001b[38;5;241m.\u001b[39mCW(model, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, kappa\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'torchattacks' is not defined"],"ename":"NameError","evalue":"name 'torchattacks' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Visualize CW attack\nvisualize_cw_attack(model, test_loader, cw)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:11:07.365620Z","iopub.status.idle":"2024-08-04T16:11:07.365914Z","shell.execute_reply.started":"2024-08-04T16:11:07.365763Z","shell.execute_reply":"2024-08-04T16:11:07.365776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}